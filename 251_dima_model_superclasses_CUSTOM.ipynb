{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-18 02:50:53.130719: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:479] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-12-18 02:50:53.244812: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:10575] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-12-18 02:50:53.245415: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1442] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-12-18 02:50:53.384621: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-12-18 02:50:55.616407: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.16.2\n",
      "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-18 02:50:57.877661: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-12-18 02:50:58.099292: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2251] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    }
   ],
   "source": [
    "############################################################################################\n",
    "# IMPORTS\n",
    "############################################################################################\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#import tensorflow.keras.backend as K\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import tensorflow as tf\n",
    "#import tensorflow.keras as keras\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import regularizers\n",
    "\n",
    "\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, Dense, MaxPooling2D, Activation, Flatten\n",
    "\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "\n",
    "\n",
    "from IPython import display\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "import pathlib\n",
    "import shutil\n",
    "import tempfile\n",
    "import concurrent\n",
    "\n",
    "\n",
    "from numba import cuda \n",
    "\n",
    "import json\n",
    "import glob\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(tf.__version__)\n",
    "print(tf.config.list_physical_devices())\n",
    "############################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################################################\n",
    "# 1. CONSTANTS - PATHS\n",
    "############################################################################################\n",
    "\n",
    "DATA_FS251 = './data/iFood_2019'\n",
    "CLASSES_FILE_NAME = '/formated_annot/classes_formated.csv'\n",
    "\n",
    "TRAIN_INFO = '/annot/train_info.csv'\n",
    "VAL_INFO = '/annot/val_info.csv'\n",
    "TEST_INFO = '/annot/test_info.csv'\n",
    "\n",
    "TRAIN_PICS_PATH = './data/iFood_2019/train_set/'\n",
    "TEST_PICS_PATH = './data/iFood_2019/test_set/'\n",
    "VAL_PICS_PATH = './data/iFood_2019/val_set/'\n",
    "\n",
    "SEED = 111\n",
    "\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>class_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train_101733.jpg</td>\n",
       "      <td>211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train_101734.jpg</td>\n",
       "      <td>211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train_101735.jpg</td>\n",
       "      <td>211</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          file_name  class_num\n",
       "0  train_101733.jpg        211\n",
       "1  train_101734.jpg        211\n",
       "2  train_101735.jpg        211"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "############################################################################################\n",
    "# IMPORTING DATA\n",
    "############################################################################################\n",
    "df_classes = pd.read_csv(DATA_FS251 + CLASSES_FILE_NAME)\n",
    "df_train = pd.read_csv(DATA_FS251 + TRAIN_INFO, names=['file_name', 'class_num'])\n",
    "df_validate = pd.read_csv(DATA_FS251 + VAL_INFO, names=['file_name', 'class_num'])\n",
    "df_test = pd.read_csv(DATA_FS251 + TEST_INFO, names=['file_name'])\n",
    "\n",
    "df_train.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################################################\n",
    "# 2. CONSTANTS - MODEL\n",
    "############################################################################################\n",
    "training_history = dict()\n",
    "\n",
    "N_TRAIN = len(df_train.iloc[:, 0])\n",
    "EPOCHS = 20\n",
    "BATCH_SIZE = 32\n",
    "RESIZE_TO = (256, 256)\n",
    "STEPS_PER_EPOCH = N_TRAIN // BATCH_SIZE\n",
    "lr_schedule = tf.keras.optimizers.schedules.InverseTimeDecay(\n",
    "    0.01,\n",
    "    decay_steps=STEPS_PER_EPOCH*1000,\n",
    "    decay_rate=1,\n",
    "    staircase=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 118475 files belonging to 251 classes.\n",
      "Found 11994 files belonging to 251 classes.\n",
      "Found 118475 files.\n"
     ]
    }
   ],
   "source": [
    "############################################################################################\n",
    "# import image files\n",
    "\n",
    "train_pics = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    TRAIN_PICS_PATH,\n",
    "    labels='inferred',\n",
    "    label_mode='categorical',\n",
    "    class_names=None,\n",
    "    color_mode='rgb',\n",
    "    batch_size=BATCH_SIZE,\n",
    "#    image_size=RESIZE_TO,\n",
    "    shuffle=False,\n",
    "    seed=SEED,\n",
    "    validation_split=None,\n",
    "    subset=None,\n",
    "#    interpolation='bilinear',\n",
    "    follow_links=False,\n",
    "    crop_to_aspect_ratio=False,\n",
    "    pad_to_aspect_ratio=True,\n",
    "    data_format=None,\n",
    "    verbose=True\n",
    ")\n",
    "val_pics = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    VAL_PICS_PATH,\n",
    "    labels='inferred',\n",
    "    label_mode='categorical',\n",
    "    class_names=None,\n",
    "    color_mode='rgb',\n",
    "    batch_size=BATCH_SIZE,\n",
    "#    image_size=RESIZE_TO,\n",
    "    shuffle=False,\n",
    "    seed=SEED,\n",
    "    validation_split=None,\n",
    "    subset=None,\n",
    "#    interpolation='bilinear',\n",
    "    follow_links=False,\n",
    "    crop_to_aspect_ratio=False,\n",
    "    pad_to_aspect_ratio=True,\n",
    "    data_format=None,\n",
    "    verbose=True\n",
    ")\n",
    "test_pics = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    TRAIN_PICS_PATH,\n",
    "    labels=None,\n",
    "    label_mode=None,\n",
    "    class_names=None,\n",
    "    color_mode='rgb',\n",
    "    batch_size=BATCH_SIZE,\n",
    "#    image_size=RESIZE_TO,\n",
    "    shuffle=False,\n",
    "    seed=SEED,\n",
    "    validation_split=None,\n",
    "    subset=None,\n",
    "#    interpolation='bilinear',\n",
    "    follow_links=False,\n",
    "    crop_to_aspect_ratio=False,\n",
    "    pad_to_aspect_ratio=True,\n",
    "    data_format=None,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#tf.keras.preprocessing.image.load_img(train_pics[155])\n",
    "#plt.imshow(train_pics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################################################\n",
    "# DEFINING THE MODEL\n",
    "tf.keras.backend.clear_session()\n",
    "model_supclass = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Resizing(\n",
    "        height = 256,\n",
    "        width = 256,\n",
    "        interpolation='bicubic',\n",
    "        crop_to_aspect_ratio=False,\n",
    "        pad_to_aspect_ratio=False,\n",
    "        fill_mode='constant',\n",
    "        fill_value=0.0,\n",
    "        data_format=None),\n",
    "# First conv. layers set 256p:\n",
    "        tf.keras.layers.Conv2D(\n",
    "                filters=250,\n",
    "                kernel_size = (3,3),\n",
    "                strides=(1, 1),\n",
    "                padding='valid',\n",
    "                data_format=None,\n",
    "                dilation_rate=(1, 1),\n",
    "                groups=1,\n",
    "                activation='relu',\n",
    "                use_bias=True,\n",
    "                kernel_initializer='glorot_uniform',\n",
    "                bias_initializer='zeros',\n",
    "                kernel_regularizer=None,\n",
    "                bias_regularizer=None,\n",
    "                activity_regularizer=None,\n",
    "                kernel_constraint=None,\n",
    "                bias_constraint=None\n",
    "        ),\n",
    "        tf.keras.layers.Conv2D(\n",
    "                filters=250,\n",
    "                kernel_size = (3,3),\n",
    "                strides=(1, 1),\n",
    "                padding='valid',\n",
    "                data_format=None,\n",
    "                dilation_rate=(1, 1),\n",
    "                groups=1,\n",
    "                activation='relu',\n",
    "                use_bias=True,\n",
    "                kernel_initializer='glorot_uniform',\n",
    "                bias_initializer='zeros',\n",
    "                kernel_regularizer=None,\n",
    "                bias_regularizer=None,\n",
    "                activity_regularizer=None,\n",
    "                kernel_constraint=None,\n",
    "                bias_constraint=None\n",
    "        ),\n",
    "# Second conv. layers set 256->128:\n",
    "        tf.keras.layers.MaxPooling2D(\n",
    "                pool_size=(2, 2),\n",
    "                strides=2,\n",
    "                padding='valid',\n",
    "                data_format=None,\n",
    "                name='256_to_128_MaxPool'\n",
    "        ),\n",
    "        tf.keras.layers.Conv2D(\n",
    "                filters=250,\n",
    "                kernel_size = (3,3),\n",
    "                strides=(1, 1),\n",
    "                padding='valid',\n",
    "                data_format=None,\n",
    "                dilation_rate=(1, 1),\n",
    "                groups=1,\n",
    "                activation='relu',\n",
    "                use_bias=True,\n",
    "                kernel_initializer='glorot_uniform',\n",
    "                bias_initializer='zeros',\n",
    "                kernel_regularizer=None,\n",
    "                bias_regularizer=None,\n",
    "                activity_regularizer=None,\n",
    "                kernel_constraint=None,\n",
    "                bias_constraint=None\n",
    "        ),\n",
    "        tf.keras.layers.Conv2D(\n",
    "                filters=250,\n",
    "                kernel_size = (3,3),\n",
    "                strides=(1, 1),\n",
    "                padding='valid',\n",
    "                data_format=None,\n",
    "                dilation_rate=(1, 1),\n",
    "                groups=1,\n",
    "                activation='relu',\n",
    "                use_bias=True,\n",
    "                kernel_initializer='glorot_uniform',\n",
    "                bias_initializer='zeros',\n",
    "                kernel_regularizer=None,\n",
    "                bias_regularizer=None,\n",
    "                activity_regularizer=None,\n",
    "                kernel_constraint=None,\n",
    "                bias_constraint=None\n",
    "        ),\n",
    "# Third conv. layers set 128->64:\n",
    "        tf.keras.layers.MaxPooling2D(\n",
    "                pool_size=(2, 2),\n",
    "                strides=2,\n",
    "                padding='valid',\n",
    "                data_format=None,\n",
    "                name='128_to_64_MaxPool'\n",
    "        ),\n",
    "        tf.keras.layers.Conv2D(\n",
    "                filters=251,\n",
    "                kernel_size = (3,3),\n",
    "                strides=(1, 1),\n",
    "                padding='valid',\n",
    "                data_format=None,\n",
    "                dilation_rate=(1, 1),\n",
    "                groups=1,\n",
    "                activation='relu',\n",
    "                use_bias=True,\n",
    "                kernel_initializer='glorot_uniform',\n",
    "                bias_initializer='zeros',\n",
    "                kernel_regularizer=None,\n",
    "                bias_regularizer=None,\n",
    "                activity_regularizer=None,\n",
    "                kernel_constraint=None,\n",
    "                bias_constraint=None\n",
    "        ),\n",
    "        tf.keras.layers.Conv2D(\n",
    "                filters=251,\n",
    "                kernel_size = (3,3),\n",
    "                strides=(1, 1),\n",
    "                padding='valid',\n",
    "                data_format=None,\n",
    "                dilation_rate=(1, 1),\n",
    "                groups=1,\n",
    "                activation='relu',\n",
    "                use_bias=True,\n",
    "                kernel_initializer='glorot_uniform',\n",
    "                bias_initializer='zeros',\n",
    "                kernel_regularizer=None,\n",
    "                bias_regularizer=None,\n",
    "                activity_regularizer=None,\n",
    "                kernel_constraint=None,\n",
    "                bias_constraint=None\n",
    "        ),\n",
    "# Third conv. layers set 64->32:\n",
    "        tf.keras.layers.MaxPooling2D(\n",
    "                pool_size=(2, 2),\n",
    "                strides=2,\n",
    "                padding='valid',\n",
    "                data_format=None,\n",
    "                name='64_to_32_MaxPool'\n",
    "        ),\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(RESIZE_TO[0],kernel_initializer = 'uniform', activation=tf.keras.activations.sigmoid),\n",
    "        tf.keras.layers.Dense(units=251,activation='softmax')\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "#model_supclass.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################################################\n",
    "# COMPILING\n",
    "############################################################################################\n",
    "model_supclass.compile(\n",
    "              optimizer = tf.keras.optimizers.Adam(learning_rate = 0.3),\n",
    "              loss = tf.keras.losses.categorical_crossentropy,\n",
    "              metrics = [tf.keras.metrics.categorical_accuracy] \n",
    "             )\n",
    "\n",
    "#model_supclass.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m   2/3703\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m45:33:09\u001b[0m 44s/step - categorical_accuracy: 0.2500 - loss: 3.6736    "
     ]
    }
   ],
   "source": [
    "############################################################################################\n",
    "# FITTING\n",
    "############################################################################################\n",
    "with tf.device('/gpu:0'):\n",
    "    model_history = model_supclass.fit(\n",
    "        train_pics,\n",
    "        epochs = EPOCHS, \n",
    "        batch_size = BATCH_SIZE, \n",
    "        validation_data = val_pics)\n",
    "\n",
    "model_supclass.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "STOP_HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################################################\n",
    "# EVALUATION\n",
    "model_history.history.keys()\n",
    "pd.DataFrame(model_history.history).plot()\n",
    "plt.legend(bbox_to_anchor = [1, 1.02])\n",
    "plt.plot(model_history.history['val_loss'])\n",
    "plt.title('Validation Loss')\n",
    "plt.xlabel('epochs')\n",
    "\n",
    "# Print out the score\n",
    "score = model.evaluate(X, y , batch_size=10, verbose=0)\n",
    "print(score, model.metrics_names)\n",
    "\n",
    "############################################################################################\n",
    "# PREDICTION\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "y_hat=model.predict(new_X)\n",
    "############################################################################################\n",
    "# SAVING MODEL\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model.save(\"model_moons.h5\")\n",
    "moons_model = load_model(\"model_moons.h5\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
